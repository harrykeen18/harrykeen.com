Contrarian opinion for most of my peers: it’s making me smarter.

I used to be a diehard in the “this is insane, I’m just delegating all my thinking to a god dam robot” camp, but now I’m much more sanguine. I think I’ve actually achieved more, learnt more and had my curiosity peaked more times with AI than I would of without it.

I first noticed the “tech dumbification effect” years ago while relying too much on Google Maps. It takes longer for me to get a mental map of a new city if I just use Google Maps the whole time. I’m delegating the hard yards of learning for the benefit of short term convenience, but then you get reliant and over time the cost builds. Knowing the bus times off by heart or knowing routes off by heart are the ways to real efficiency. The longer you take to learn it, the longer it takes to achieve that efficiency and you’ll be less able to leverage that knowledge to make natural connections like, the train is 10 mins delayed, so I’ll grab a bus halfway and walk the rest of the way through the park. No matter how good Google Maps gets, it’s still not perfect and still can’t encapsulate your very specific preferences.

So does this model actually transfer across to AI. No, I don’t think it does. Sure there are lots of ways to rely on AI that will directly lead to you missing out on doing the hard yards, but the additive effect you get turns it to a net gain. Such as:
- Taking on tasks I would have had to outsource to an expert such as accountant and therefore learning about that specialism in the process. Dependant on the task clearly you might have to outsource, but starting from an educated position is a HUGE benefit.
- Coding. Man, these tools are great at coding now. In the hands of a well intentioned amateur, despite what people say, I really think you can produce pro level code. I have 100% taken on more ambitious tasks and learnt loads through the process.
- Asking stupid questions. I always thought of myself quite good at asking stupid questions without really caring what people think. But, I admit, there is a limit. I can ask the dumbest question to Claude/ChatGPT and it gives me ZERO judgement. I’ve got nothing to prove to ChatGPT so I can ask its whatever I want and it will comfortingly tell me that “that’s a great question”.
- Just a better search. I’m tired of wading through ad optimised pages or scrolling past 3/4’s of a page of ads on Google to get to the actual information you want.

All these things combined I think result in a knowledge democratisation and ultimately give me the confidence to do/try things I probably wouldn’t have done.

Sure, there are caveats:
- Hallucinations. Yup, they get stuff wrong the whole time. Always check out the references.
- Writing is thinking, do not delegate this. Avoid the "make this sound sharper" tools, you MUST learn this yourself. This is more like the Google Maps example.

Use AI with curiosity and treat it like a genius professor in your pocket with unlimited patience, but a professor you treat with a little bit of skepticism and I think, like me, you’ll learn hell of a lot.
